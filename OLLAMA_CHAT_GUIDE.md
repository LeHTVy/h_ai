# ğŸ’¬ HÆ°á»›ng dáº«n Chat vá»›i Ollama LLM qua H-AI

Báº¡n cÃ³ thá»ƒ chat trá»±c tiáº¿p vá»›i LLM (Ollama) qua H-AI API Ä‘á»ƒ há»i cÃ¡c cÃ¢u há»i phá»©c táº¡p vá» cybersecurity, exploit development, tool usage, v.v.

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. Khá»Ÿi Ä‘á»™ng server vá»›i Ollama

```bash
./bin/h-ai-server --ollama-model llama2 --port 8888
```

### 2. Chat Ä‘Æ¡n giáº£n (má»™t láº§n)

```bash
curl -X POST http://localhost:8888/api/intelligence/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {
        "role": "user",
        "content": "Giáº£i thÃ­ch cÃ¡ch SQL injection hoáº¡t Ä‘á»™ng vÃ  cÃ¡ch phÃ²ng chá»‘ng"
      }
    ]
  }'
```

### 3. Chat vá»›i nhiá»u tin nháº¯n (conversation)

```bash
curl -X POST http://localhost:8888/api/intelligence/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {
        "role": "system",
        "content": "Báº¡n lÃ  má»™t chuyÃªn gia cybersecurity vá»›i 20 nÄƒm kinh nghiá»‡m."
      },
      {
        "role": "user",
        "content": "TÃ´i cáº§n exploit CVE-2023-1234, báº¡n cÃ³ thá»ƒ hÆ°á»›ng dáº«n khÃ´ng?"
      },
      {
        "role": "assistant",
        "content": "Äá»ƒ exploit CVE-2023-1234, báº¡n cáº§n..."
      },
      {
        "role": "user",
        "content": "Váº­y lÃ m sao Ä‘á»ƒ táº¡o payload?"
      }
    ]
  }'
```

### 4. Äiá»u chá»‰nh Temperature vÃ  TopP

```bash
curl -X POST http://localhost:8888/api/intelligence/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {
        "role": "user",
        "content": "Viáº¿t má»™t exploit Python cho buffer overflow"
      }
    ],
    "temperature": 0.3,
    "top_p": 0.9
  }'
```

**Temperature:**
- `0.0-0.3`: CÃ³ cáº¥u trÃºc, chÃ­nh xÃ¡c (tá»‘t cho code, exploit)
- `0.4-0.7`: CÃ¢n báº±ng (máº·c Ä‘á»‹nh)
- `0.8-1.0`: SÃ¡ng táº¡o, Ä‘a dáº¡ng (tá»‘t cho brainstorming)

**TopP:**
- `0.1-0.5`: Táº­p trung vÃ o top tokens
- `0.6-0.9`: Äa dáº¡ng hÆ¡n (máº·c Ä‘á»‹nh 0.9)
- `1.0`: Táº¥t cáº£ tokens

## ğŸ“ VÃ­ dá»¥ sá»­ dá»¥ng thá»±c táº¿

### 1. Há»i vá» Security Tools

```bash
curl -X POST http://localhost:8888/api/intelligence/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {
        "role": "user",
        "content": "LÃ m sao Ä‘á»ƒ dÃ¹ng Nmap Ä‘á»ƒ scan stealthy nháº¥t cÃ³ thá»ƒ? Cho tÃ´i command cá»¥ thá»ƒ."
      }
    ],
    "temperature": 0.2
  }'
```

### 2. PhÃ¢n tÃ­ch Vulnerability

```bash
curl -X POST http://localhost:8888/api/intelligence/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {
        "role": "user",
        "content": "TÃ´i Ä‘Ã£ scan vÃ  tháº¥y port 443 má»Ÿ vá»›i Apache 2.4.41. CÃ³ nhá»¯ng lá»— há»•ng nÃ o tÃ´i nÃªn kiá»ƒm tra?"
      }
    ],
    "temperature": 0.3
  }'
```

### 3. Viáº¿t Exploit Code

```bash
curl -X POST http://localhost:8888/api/intelligence/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {
        "role": "system",
        "content": "Báº¡n lÃ  má»™t exploit developer chuyÃªn nghiá»‡p. Viáº¿t code Python rÃµ rÃ ng, cÃ³ comment."
      },
      {
        "role": "user",
        "content": "Viáº¿t exploit cho buffer overflow trÃªn port 9999, cÃ³ thá»ƒ overflow 200 bytes."
      }
    ],
    "temperature": 0.2,
    "top_p": 0.8
  }'
```

### 4. Há»i vá» Attack Chain

```bash
curl -X POST http://localhost:8888/api/intelligence/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {
        "role": "user",
        "content": "TÃ´i Ä‘Ã£ cÃ³ shell trÃªn má»™t web server Linux. BÃ¢y giá» tÃ´i cáº§n privilege escalation. HÃ£y Ä‘Æ°a ra má»™t attack chain chi tiáº¿t tá»«ng bÆ°á»›c."
      }
    ]
  }'
```

### 5. PhÃ¢n tÃ­ch Káº¿t quáº£ Scan

```bash
curl -X POST http://localhost:8888/api/intelligence/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {
        "role": "user",
        "content": "TÃ´i scan má»™t target vÃ  tháº¥y:\n- Port 22: OpenSSH 7.4\n- Port 80: Apache 2.4.6\n- Port 3306: MySQL 5.7\n- Port 8080: Tomcat 8.5\n\nHÃ£y phÃ¢n tÃ­ch vÃ  Ä‘Æ°a ra káº¿ hoáº¡ch táº¥n cÃ´ng chi tiáº¿t."
      }
    ],
    "temperature": 0.4
  }'
```

## ğŸ”§ Sá»­ dá»¥ng vá»›i Python

```python
import requests
import json

def chat_with_hai(prompt, conversation_history=None, temperature=0.7):
    url = "http://localhost:8888/api/intelligence/chat"
    
    messages = conversation_history or []
    messages.append({
        "role": "user",
        "content": prompt
    })
    
    payload = {
        "messages": messages,
        "temperature": temperature
    }
    
    response = requests.post(url, json=payload)
    return response.json()

# VÃ­ dá»¥ sá»­ dá»¥ng
result = chat_with_hai("Giáº£i thÃ­ch cÃ¡ch XSS hoáº¡t Ä‘á»™ng")
print(result["response"])

# Conversation
history = [
    {"role": "user", "content": "CVE-2023-1234 lÃ  gÃ¬?"},
    {"role": "assistant", "content": "CVE-2023-1234 lÃ  má»™t lá»— há»•ng..."}
]
result = chat_with_hai("LÃ m sao Ä‘á»ƒ exploit?", history)
print(result["response"])
```

## ğŸ”§ Sá»­ dá»¥ng vá»›i JavaScript/Node.js

```javascript
async function chatWithHAI(prompt, conversationHistory = null, temperature = 0.7) {
  const url = 'http://localhost:8888/api/intelligence/chat';
  
  const messages = conversationHistory || [];
  messages.push({
    role: 'user',
    content: prompt
  });
  
  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      messages: messages,
      temperature: temperature
    })
  });
  
  return await response.json();
}

// Sá»­ dá»¥ng
const result = await chatWithHAI('Giáº£i thÃ­ch cÃ¡ch SQL injection hoáº¡t Ä‘á»™ng');
console.log(result.response);
```

## ğŸ¯ Best Practices

1. **System Prompt**: Sá»­ dá»¥ng `role: "system"` Ä‘á»ƒ set context cho LLM
   ```json
   {
     "role": "system",
     "content": "Báº¡n lÃ  má»™t penetration tester chuyÃªn nghiá»‡p..."
   }
   ```

2. **Temperature tháº¥p cho code**: Khi cáº§n code chÃ­nh xÃ¡c, dÃ¹ng `temperature: 0.2-0.3`

3. **Conversation History**: Giá»¯ láº¡i lá»‹ch sá»­ Ä‘á»ƒ LLM hiá»ƒu context

4. **Chia nhá» cÃ¢u há»i phá»©c táº¡p**: Thay vÃ¬ má»™t cÃ¢u há»i dÃ i, chia thÃ nh nhiá»u cÃ¢u ngáº¯n hÆ¡n

5. **Kiá»ƒm tra response**: LuÃ´n kiá»ƒm tra `success: true` trÆ°á»›c khi dÃ¹ng response

## ğŸ“Š Response Format

```json
{
  "success": true,
  "response": "CÃ¢u tráº£ lá»i tá»« LLM...",
  "message_count": 1
}
```

Hoáº·c náº¿u cÃ³ lá»—i:
```json
{
  "success": false,
  "error": "Ollama AI is not available",
  "message": "Please configure --ollama-url and --ollama-model flags..."
}
```

## âš ï¸ LÆ°u Ã½

- **Timeout**: Máº·c Ä‘á»‹nh timeout lÃ  120 giÃ¢y. CÃ¢u há»i phá»©c táº¡p cÃ³ thá»ƒ cáº§n thá»i gian lÃ¢u hÆ¡n
- **Model size**: Model lá»›n (13B+) sáº½ chÃ­nh xÃ¡c hÆ¡n nhÆ°ng cháº­m hÆ¡n
- **RAM**: Äáº£m báº£o cÃ³ Ä‘á»§ RAM cho model (thÆ°á»ng cáº§n 8-16GB cho model 7B-13B)
- **Context length**: Má»™t sá»‘ model cÃ³ giá»›i háº¡n Ä‘á»™ dÃ i context, chia nhá» conversation náº¿u quÃ¡ dÃ i

## ğŸ”— Káº¿t há»£p vá»›i H-AI Tools

Báº¡n cÃ³ thá»ƒ káº¿t há»£p chat vá»›i cÃ¡c tools cá»§a H-AI:

```bash
# 1. Scan target
curl -X POST http://localhost:8888/api/tools/nmap \
  -d '{"target": "example.com"}' > scan_results.json

# 2. Há»i LLM vá» káº¿t quáº£ scan
curl -X POST http://localhost:8888/api/intelligence/chat \
  -d '{
    "messages": [{
      "role": "user",
      "content": "TÃ´i scan Ä‘Æ°á»£c káº¿t quáº£ sau, hÃ£y phÃ¢n tÃ­ch:\n'$(cat scan_results.json)'"
    }]
  }'
```

Happy hacking! ğŸš€

